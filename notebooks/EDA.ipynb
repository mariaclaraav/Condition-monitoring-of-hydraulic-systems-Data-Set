{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.ticker as ticker\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "\n",
    "# Define the current directory and add it to the system path\n",
    "current_dir = os.getcwd()\n",
    "current_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "sys.path.append(current_dir)\n",
    "\n",
    "print('Current directory: ', current_dir)\n",
    "print()\n",
    "\n",
    "image_path = os.path.join(current_dir, 'figures', 'diagram.png')\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "from src.utils.statistics import describe_data, fill_outliers\n",
    "from src.utils.visualization import tplot, descplot, descplot_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the dataset\n",
    "\n",
    "The data set was experimentally obtained using a hydraulic test rig. This test rig consists of a primary working circuit and a secondary cooling-filtration circuit connected via the oil tank. The system cyclically repeats constant load cycles (duration 60 seconds) and measures process values such as pressures, volume flows, and temperatures while the condition of four hydraulic components (cooler, valve, pump, and accumulator) is quantitatively varied.\n",
    "\n",
    "Attribute Information\n",
    "The data set contains raw process sensor data structured with the rows representing the cycles and the columns representing the data points within a cycle. All sensors were oversampled in the ETL file and now have a uniform sampling rate of 100 Hz. The sensors involved are show in the diagram bellow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename=image_path, width=800))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "The objective of this analysis is to monitor internal pump leakage (MP1), which can be classified into three categories:\n",
    "- 0: No leakage\n",
    "- 1: Weak leakage\n",
    "- 2: Severe leakage\n",
    "\n",
    "The target condition values are cycle-wise annotated in the `profile.txt` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(current_dir, 'data','processed','etl')\n",
    "\n",
    "# List of sensor file names\n",
    "sensores_list = ['PS1','PS2','PS3','PS4','PS5','PS6',\n",
    "                 'EPS1','FS1','FS2',\n",
    "                 'TS1','TS2','TS3','TS4',\n",
    "                 'VS1','CE','CP','SE','profile']\n",
    "\n",
    "# Dictionary to store the data\n",
    "X_dict = {}\n",
    "\n",
    "# Load sensor data from parquet files\n",
    "for s in tqdm(sensores_list, desc=\"Loading sensor data\"):\n",
    "    file_path = os.path.join(data_dir, s + '.parquet')\n",
    "    X_dict[s] = pd.read_parquet(file_path)\n",
    "\n",
    "# Just to check the loaded data\n",
    "for sensor, data in X_dict.items():\n",
    "    print(f\"{sensor} data shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in X_dict.items():\n",
    "    print('how nan ' + str(k) + ' = ' + str((X_dict[k].isnull().sum(axis=1) != 0).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dict['profile'].rename(columns={'2': 'profile'}, inplace=True)\n",
    "X_profile = X_dict['profile']['profile']\n",
    "X_profile = pd.DataFrame(X_profile)\n",
    "\n",
    "if 'profile' in X_dict:\n",
    "    del X_dict['profile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c, u in zip(X_dict.keys(), ['Pressure (bar)', 'Pressure (bar)', 'Pressure (bar)', 'Pressure (bar)', 'Pressure (bar)', 'Pressure (bar)','Power (W)',\n",
    "                                'Flow Rate (L/min)', 'Flow Rate (L/min)', 'Temperature (°C)', 'Temperature (°C)', 'Temperature (°C)', 'Temperature (°C)','Vibration (mm/s)', 'Cooler Efficiency (%)', 'Cooler Power (kW)', 'Efficiency Factor (%)']):\n",
    "    tplot(X_dict[c], c, u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Observing the boxplots above, we can infer that the pressure variables exhibit numerous outliers. This is evident as they vary across a wide range, which is not typical behavior for pressure measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in X_dict.items():\n",
    "    X_dict[k] = fill_outliers(v, k, c = 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c, u in zip(X_dict.keys(), ['Pressure (bar)', 'Pressure (bar)', 'Pressure (bar)', 'Pressure (bar)', 'Pressure (bar)', 'Pressure (bar)','Power (W)',\n",
    "                                'Flow Rate (L/min)', 'Flow Rate (L/min)', 'Temperature (°C)', 'Temperature (°C)', 'Temperature (°C)', 'Temperature (°C)','Vibration (mm/s)', 'Cooler Efficiency (%)', 'Cooler Power (kW)', 'Efficiency Factor (%)']):\n",
    "    tplot(X_dict[c], c, u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have multiple measurements per time instance, let's compute statistical metrics for each measurement (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the descriptive statistics\n",
    "for k, v in X_dict.items():\n",
    "    X_dict[k] = describe_data(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c, u in zip(X_dict.keys(), ['Pressure (bar)', 'Pressure (bar)', 'Pressure (bar)', 'Pressure (bar)', 'Pressure (bar)', 'Pressure (bar)','Power (W)',\n",
    "                                'Flow Rate (L/min)', 'Flow Rate (L/min)', 'Temperature (°C)', 'Temperature (°C)', 'Temperature (°C)', 'Temperature (°C)','Vibration (mm/s)', 'Cooler Efficiency (%)', 'Cooler Power (kW)', 'Efficiency Factor (%)']):\n",
    "    descplot(X_dict[c], c, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c, u in zip(X_dict.keys(), ['Pressure (bar)', 'Pressure (bar)', 'Pressure (bar)', 'Pressure (bar)', 'Pressure (bar)', 'Pressure (bar)','Power (W)',\n",
    "#                                 'Flow Rate (L/min)', 'Flow Rate (L/min)', 'Temperature (°C)', 'Temperature (°C)', 'Temperature (°C)', 'Temperature (°C)','Vibration (mm/s)', 'Cooler Efficiency (%)', 'Cooler Power (kW)', 'Efficiency Factor (%)']):\n",
    "#     descplot_2(X_dict[c], c, u, X_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6, 3, figsize=(14, 30))\n",
    "for (k,v), ax in zip(X_dict.items(), axs.reshape(-1)):\n",
    "    sns.heatmap(v.assign(profile=X_profile).corr()[['profile']], vmin=-1, vmax=1, annot=True, cmap='seismic', annot_kws={\"size\": 14}, ax=ax)\n",
    "    ax.set_title('Correlation Profile and ' + k, fontsize=12)\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "    ax.tick_params(axis='x', labelsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6, 3, figsize=(14, 30))\n",
    "\n",
    "for (k, v), ax in zip(X_dict.items(), axs.reshape(-1)):\n",
    "    sns.heatmap(v.assign(profile=X_profile).corr(method='spearman')[['profile']], \n",
    "                vmin=-1, vmax=1, annot=True, cmap='seismic', annot_kws={\"size\": 14}, ax=ax)\n",
    "    ax.set_title('Spearman Correlation Profile and ' + k, fontsize=12)\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "    ax.tick_params(axis='x', labelsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir = os.path.join(current_dir, '../data/processed/features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_parquet(data_dict, directory):\n",
    "    for key, data in data_dict.items():\n",
    "        file_path = os.path.join(directory, f'{key}.parquet')\n",
    "        data.columns = [str(col) for col in data.columns]  # Ensure column names are strings\n",
    "        data.to_parquet(file_path, index=False)\n",
    "    \n",
    "        \n",
    "save_to_parquet(X_dict, processed_dir)\n",
    "print('\\nData saved to parquet format\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
